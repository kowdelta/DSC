{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import cycle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cons_data= np.load('../high_psi dataset/x_cons_data.npy')\n",
    "\n",
    "hx_cas_data= np.load('../high_psi dataset/x_cas_data.npy')\n",
    "lx_cas_data= np.load('../low_psi_data/x_cas_data.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39128, 283, 5), (4952, 283, 5), (6838, 283, 5))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cons_data.shape,hx_cas_data.shape,lx_cas_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auccc=np.zeros((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_split(x_cons_data,hx_cas_data,lxcase_data,s):\n",
    "    \n",
    "    a=int(x_cons_data.shape[0]/10)\n",
    "    b=int(hx_cas_data.shape[0]/10)\n",
    "    c=int(lx_cas_data.shape[0]/10)\n",
    "    \n",
    "    #9 folds for training\n",
    "    train=x_cons_data[:a*s]\n",
    "    train=np.concatenate((train,x_cons_data[a*(s+1):]),axis=0)\n",
    "\n",
    "    d=int((9*a)/(9*(b+c)))\n",
    "    print(d)\n",
    "    for i in range (d):\n",
    "        train=np.concatenate((train,hx_cas_data[:b*s]),axis=0)\n",
    "        train=np.concatenate((train,hx_cas_data[b*(s+1):]),axis=0)\n",
    "    \n",
    "        train=np.concatenate((train,lx_cas_data[:c*s]),axis=0)\n",
    "        train=np.concatenate((train,lx_cas_data[c*(s+1):]),axis=0)\n",
    "      \n",
    "    np.random.shuffle(train)\n",
    "    np.random.shuffle(train)\n",
    "    \n",
    "    # 1 fold for testing\n",
    "    \n",
    "    htest=np.concatenate((hx_cas_data[b*s:b*(s+1)],x_cons_data[a*s:a*(s+1)]),axis=0)\n",
    "    lt=   np.concatenate((lx_cas_data[c*s:c*(s+1)],x_cons_data[a*s:a*(s+1)]),axis=0)\n",
    "\n",
    "    test=htest\n",
    "    test=np.concatenate((test,lx_cas_data[c*s:c*(s+1)]),axis=0)\n",
    "    \n",
    "    cons_test=x_cons_data[a*s:a*(s+1)]\n",
    "    cas_test=np.concatenate((lx_cas_data[c*s:c*(s+1)],hx_cas_data[b*s:b*(s+1)]))\n",
    "                          \n",
    "    return train,test,htest,lt,cons_test,cas_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((67052, 283, 5), (5090, 283, 5), (4407, 283, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,test,htest,ltest,cons,cas=cross_split(x_cons_data,hx_cas_data,lx_cas_data,0)\n",
    "\n",
    "y_train=train[:,l-1,0]\n",
    "y_test=test[:,l-1,0]\n",
    "hy_test=htest[:,l-1,0]\n",
    "ly_test=ltest[:,l-1,0]\n",
    "\n",
    "train.shape,test.shape,htest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_AUC2():\n",
    "    psi=cas[:,-1,4]\n",
    "    roc_auc=np.zeros(5)\n",
    "    colors = cycle(['black','green','red','orange','blue'])\n",
    "    f=plt.figure()\n",
    "\n",
    "    \n",
    "    for i, color in zip(range(5), colors):\n",
    "    \n",
    "        \n",
    "        ptest=cas[ (psi >=i*2*0.1) & (psi< (i+1)*2*0.1)  ]\n",
    "        ptest=np.concatenate((ptest,cons),axis=0)\n",
    "        py_test=ptest[:,l-1,0]\n",
    "\n",
    "        ypreds=model.predict([ptest[:,:l-1,:4],ptest[:,l:(l*2)-1,:4],ptest[:,-1,0:3]])\n",
    "        fpr, tpr, thresholds = roc_curve(py_test, ypreds)\n",
    "        roc_auc[i] = auc(fpr, tpr)\n",
    "        lw=2\n",
    "\n",
    "        plt.plot(fpr, tpr, color=color, lw=lw,\n",
    "                 label='Inclusion level %d-%d %% (AUC= %0.2f)' % (i*2*10,(i+1)*2*10,roc_auc[i]))\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    f.savefig(\"../plots/cas2.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    roc_auc=np.zeros(10)\n",
    "\n",
    "    for i in range(10):\n",
    "            ptest=cas[(psi >=i*0.1) & (psi< (i+1)*0.1)]\n",
    "            ptest=np.concatenate((ptest,cons),axis=0)\n",
    "            py_test=ptest[:,l-1,0]\n",
    "\n",
    "            ypreds=model.predict([ptest[:,:l-1,:4],ptest[:,l:(l*2)-1,:4],ptest[:,-1,0:3]])\n",
    "            fpr, tpr, thresholds = roc_curve(py_test, ypreds)\n",
    "            roc_auc[i] = auc(fpr, tpr)\n",
    "\n",
    "    \n",
    "    return roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_AUC():\n",
    "    ypreds=model.predict([htest[:,:l-1,:4],htest[:,l:(l*2)-1,:4],htest[:,-1,0:3]])\n",
    "    fpr, tpr, thresholds = roc_curve(hy_test, ypreds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    ypreds2=model.predict([test[:,:l-1,:4],test[:,l:(l*2)-1,:4],test[:,-1,0:3]])\n",
    "    fpr2, tpr2, thresholds2 = roc_curve(y_test, ypreds2)\n",
    "    roc_auc2 = auc(fpr2, tpr2)\n",
    "    \n",
    "    ypreds3=model.predict([ltest[:,:l-1,:4],ltest[:,l:(l*2)-1,:4],ltest[:,-1,0:3]])\n",
    "    fpr3, tpr3, thresholds3 = roc_curve(ly_test, ypreds3)\n",
    "    roc_auc3 = auc(fpr3, tpr3)\n",
    "    \n",
    "\n",
    "    lw=2\n",
    "    \n",
    "    \n",
    "    \n",
    "    f=plt.figure()\n",
    "    plt.plot(fpr2, tpr2, color='orange', lw=1, label=    'All ES events (AUC= %0.2f)' % roc_auc2)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color='red', lw=1,          label='HEvents ES subset (AUC= %0.2f)' % roc_auc)\n",
    "    \n",
    "    plt.plot(fpr3, tpr3, color='navy', lw=1,       label='MREvents ES subset (AUC= %0.2f)' % roc_auc3)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    f.savefig(\"../plots/cas.pdf\", bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, BatchNormalization\n",
    "from keras.models import Model\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from keras import initializers\n",
    "from keras.layers import Activation, Dense, Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucc=np.zeros((10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 140, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 140, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 134, 32)      928         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 134, 32)      928         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 134, 32)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 134, 32)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 134, 32)      0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 134, 32)      0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 67, 32)       0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 67, 32)       0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 64, 8)        1032        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 64, 8)        1032        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64, 8)        0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 8)        0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 8)        0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 8)        0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 32, 8)        0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 32, 8)        0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 30, 8)        200         max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 30, 8)        200         max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 30, 8)        0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 30, 8)        0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 30, 8)        0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 30, 8)        0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 15, 8)        0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 15, 8)        0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 15, 16)       0           max_pooling1d_6[0][0]            \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 240)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 243)          0           flatten_1[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           15616       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            65          dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,001\n",
      "Trainable params: 20,001\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs1 = Input(shape=(l-1, 4))\n",
    "inputs2 = Input(shape=(l-1, 4))\n",
    "inputs3 = Input(shape=(3,))\n",
    "\n",
    "\n",
    "x=Conv1D(filters=32,kernel_size=7,strides=1,kernel_initializer=initializers.random_uniform()) (inputs1)\n",
    "x=Dropout(0.2)(x)\n",
    "x=Activation('relu')(x)\n",
    "x=MaxPooling1D(pool_size=2, strides=2)(x)\n",
    "\n",
    "x=Conv1D(filters=8,kernel_size=4,strides=1,kernel_initializer=initializers.random_uniform()) (x)\n",
    "x=Dropout(0.2)(x)\n",
    "x=Activation('relu')(x)\n",
    "x=MaxPooling1D(pool_size=2, strides=2)(x)\n",
    "\n",
    "\n",
    "x=Conv1D(filters=8,kernel_size=3,strides=1,kernel_initializer=initializers.random_uniform()) (x)\n",
    "x=Dropout(0.2)(x)\n",
    "x=Activation('relu')(x)\n",
    "x=MaxPooling1D(pool_size=2, strides=2)(x)\n",
    "\n",
    "\n",
    "xx=Conv1D(filters=32,kernel_size=7,strides=1,kernel_initializer=initializers.random_uniform()) (inputs2)\n",
    "xx=Dropout(0.2)(xx)\n",
    "xx=Activation('relu')(xx)\n",
    "xx=MaxPooling1D(pool_size=2, strides=2)(xx)\n",
    "\n",
    "xx=Conv1D(filters=8,kernel_size=4,strides=1,kernel_initializer=initializers.random_uniform()) (xx)\n",
    "xx=Dropout(0.2)(xx)\n",
    "xx=Activation('relu')(xx)\n",
    "xx=MaxPooling1D(pool_size=2, strides=2)(xx)\n",
    "\n",
    "\n",
    "xx=Conv1D(filters=8,kernel_size=3,strides=1,kernel_initializer=initializers.random_uniform()) (xx)\n",
    "xx=Dropout(0.2)(xx)\n",
    "xx=Activation('relu')(xx)\n",
    "xx=MaxPooling1D(pool_size=2, strides=2)(xx)\n",
    "\n",
    "\n",
    "x2=keras.layers.concatenate([xx,x])\n",
    "\n",
    "\n",
    "\n",
    "x2=Flatten()(x2)\n",
    "\n",
    "\n",
    "x2=keras.layers.concatenate([x2,inputs3],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x3=Dense(64, activation='relu',)(x2)\n",
    "x3=Dropout(0.5)(x3)\n",
    "\n",
    "\n",
    "x3=Dense(1, activation='sigmoid',  )(x3)\n",
    "\n",
    "\n",
    "model = Model(inputs=[inputs1,inputs2,inputs3], outputs=x3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(lr=0.0005,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.999,\n",
    "                                        epsilon=1e-08,\n",
    "                                        decay=0.0),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "print (model.summary())\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_w2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 11s 167us/step - loss: 0.6837 - acc: 0.5623 - val_loss: 0.6415 - val_acc: 0.7122\n",
      "AUC under ROC for high inclusion exons: 0.5673728594740864\n",
      "epoch : 1\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.6646 - acc: 0.6112 - val_loss: 0.6150 - val_acc: 0.7297\n",
      "AUC under ROC for high inclusion exons: 0.5877628534837123\n",
      "epoch : 2\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.6417 - acc: 0.6404 - val_loss: 0.6072 - val_acc: 0.6963\n",
      "AUC under ROC for high inclusion exons: 0.6079731362706823\n",
      "epoch : 3\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.6216 - acc: 0.6588 - val_loss: 0.5887 - val_acc: 0.7100\n",
      "AUC under ROC for high inclusion exons: 0.6324058581727293\n",
      "epoch : 4\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.6056 - acc: 0.6783 - val_loss: 0.5599 - val_acc: 0.7538\n",
      "AUC under ROC for high inclusion exons: 0.6460355084588214\n",
      "epoch : 5\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.5934 - acc: 0.6900 - val_loss: 0.5540 - val_acc: 0.7536\n",
      "AUC under ROC for high inclusion exons: 0.6601567825494207\n",
      "epoch : 6\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.5838 - acc: 0.6990 - val_loss: 0.5186 - val_acc: 0.8026\n",
      "AUC under ROC for high inclusion exons: 0.6767490859515399\n",
      "epoch : 7\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.5738 - acc: 0.7090 - val_loss: 0.5350 - val_acc: 0.7729\n",
      "AUC under ROC for high inclusion exons: 0.6891698167771787\n",
      "epoch : 8\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.5605 - acc: 0.7213 - val_loss: 0.5085 - val_acc: 0.8071\n",
      "AUC under ROC for high inclusion exons: 0.7158646795149861\n",
      "epoch : 9\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.5522 - acc: 0.7299 - val_loss: 0.5128 - val_acc: 0.7933\n",
      "AUC under ROC for high inclusion exons: 0.73005463634298\n",
      "epoch : 10\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.5411 - acc: 0.7373 - val_loss: 0.5231 - val_acc: 0.7766\n",
      "AUC under ROC for high inclusion exons: 0.7452484972423623\n",
      "epoch : 11\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.5314 - acc: 0.7482 - val_loss: 0.5390 - val_acc: 0.7532\n",
      "AUC under ROC for high inclusion exons: 0.7645586746813742\n",
      "epoch : 12\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.5211 - acc: 0.7570 - val_loss: 0.4995 - val_acc: 0.7961\n",
      "AUC under ROC for high inclusion exons: 0.761765920968375\n",
      "epoch : 13\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.5102 - acc: 0.7620 - val_loss: 0.4831 - val_acc: 0.8094\n",
      "AUC under ROC for high inclusion exons: 0.768883879696763\n",
      "epoch : 14\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.5025 - acc: 0.7679 - val_loss: 0.4749 - val_acc: 0.8179\n",
      "AUC under ROC for high inclusion exons: 0.7879451467641652\n",
      "epoch : 15\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.4930 - acc: 0.7738 - val_loss: 0.4808 - val_acc: 0.8049\n",
      "AUC under ROC for high inclusion exons: 0.7902906880667617\n",
      "epoch : 16\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.4854 - acc: 0.7784 - val_loss: 0.4683 - val_acc: 0.8118\n",
      "AUC under ROC for high inclusion exons: 0.7947029084299023\n",
      "epoch : 17\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.4774 - acc: 0.7819 - val_loss: 0.4901 - val_acc: 0.7894\n",
      "AUC under ROC for high inclusion exons: 0.7988620871289583\n",
      "epoch : 18\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.4707 - acc: 0.7862 - val_loss: 0.5186 - val_acc: 0.7525\n",
      "AUC under ROC for high inclusion exons: 0.8007113569230133\n",
      "epoch : 19\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.4646 - acc: 0.7881 - val_loss: 0.4653 - val_acc: 0.8059\n",
      "AUC under ROC for high inclusion exons: 0.7996000392472786\n",
      "epoch : 20\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.4593 - acc: 0.7935 - val_loss: 0.4302 - val_acc: 0.8377\n",
      "AUC under ROC for high inclusion exons: 0.8036776249199562\n",
      "epoch : 21\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.4534 - acc: 0.7955 - val_loss: 0.4800 - val_acc: 0.7900\n",
      "AUC under ROC for high inclusion exons: 0.8002156018260312\n",
      "epoch : 22\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.4476 - acc: 0.7985 - val_loss: 0.4868 - val_acc: 0.7776\n",
      "AUC under ROC for high inclusion exons: 0.8056133936502036\n",
      "epoch : 23\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.4454 - acc: 0.7984 - val_loss: 0.4785 - val_acc: 0.7864\n",
      "AUC under ROC for high inclusion exons: 0.8109352729751502\n",
      "epoch : 24\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.4385 - acc: 0.8026 - val_loss: 0.4470 - val_acc: 0.8116\n",
      "AUC under ROC for high inclusion exons: 0.8075811798971307\n",
      "epoch : 25\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.4342 - acc: 0.8037 - val_loss: 0.4466 - val_acc: 0.8134\n",
      "AUC under ROC for high inclusion exons: 0.8117839953729524\n",
      "epoch : 26\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.4305 - acc: 0.8049 - val_loss: 0.4644 - val_acc: 0.7935\n",
      "AUC under ROC for high inclusion exons: 0.8145597075044927\n",
      "epoch : 27\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.4269 - acc: 0.8087 - val_loss: 0.4806 - val_acc: 0.7776\n",
      "AUC under ROC for high inclusion exons: 0.8068057879407572\n",
      "epoch : 28\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.4246 - acc: 0.8096 - val_loss: 0.4518 - val_acc: 0.8022\n",
      "AUC under ROC for high inclusion exons: 0.8073325277313008\n",
      "epoch : 29\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.4226 - acc: 0.8104 - val_loss: 0.4403 - val_acc: 0.8141\n",
      "AUC under ROC for high inclusion exons: 0.8147776331825411\n",
      "epoch : 30\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.4172 - acc: 0.8122 - val_loss: 0.4522 - val_acc: 0.7988\n",
      "AUC under ROC for high inclusion exons: 0.8086207163661151\n",
      "epoch : 31\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.4150 - acc: 0.8141 - val_loss: 0.4616 - val_acc: 0.7941\n",
      "AUC under ROC for high inclusion exons: 0.8128359257193611\n",
      "epoch : 32\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.4116 - acc: 0.8150 - val_loss: 0.4540 - val_acc: 0.7969\n",
      "AUC under ROC for high inclusion exons: 0.813929685402078\n",
      "epoch : 33\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.4095 - acc: 0.8165 - val_loss: 0.4746 - val_acc: 0.7833\n",
      "AUC under ROC for high inclusion exons: 0.8076787816818491\n",
      "epoch : 34\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.4055 - acc: 0.8196 - val_loss: 0.4297 - val_acc: 0.8108\n",
      "AUC under ROC for high inclusion exons: 0.8104751502757637\n",
      "epoch : 35\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.4045 - acc: 0.8182 - val_loss: 0.4908 - val_acc: 0.7717\n",
      "AUC under ROC for high inclusion exons: 0.8136133833219722\n",
      "epoch : 36\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 52us/step - loss: 0.4024 - acc: 0.8186 - val_loss: 0.4284 - val_acc: 0.8149\n",
      "AUC under ROC for high inclusion exons: 0.8181784615066824\n",
      "epoch : 37\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.4000 - acc: 0.8190 - val_loss: 0.4201 - val_acc: 0.8167\n",
      "AUC under ROC for high inclusion exons: 0.8145917250211729\n",
      "epoch : 38\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.4002 - acc: 0.8196 - val_loss: 0.4688 - val_acc: 0.7866\n",
      "AUC under ROC for high inclusion exons: 0.8153596290099359\n",
      "epoch : 39\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3970 - acc: 0.8220 - val_loss: 0.4633 - val_acc: 0.7894\n",
      "AUC under ROC for high inclusion exons: 0.8137649501146434\n",
      "epoch : 40\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3935 - acc: 0.8228 - val_loss: 0.4054 - val_acc: 0.8308\n",
      "AUC under ROC for high inclusion exons: 0.8196133110243541\n",
      "epoch : 41\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3931 - acc: 0.8233 - val_loss: 0.4301 - val_acc: 0.8098\n",
      "AUC under ROC for high inclusion exons: 0.813022350292289\n",
      "epoch : 42\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3920 - acc: 0.8244 - val_loss: 0.4576 - val_acc: 0.7945\n",
      "AUC under ROC for high inclusion exons: 0.8130572080725456\n",
      "epoch : 43\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.3907 - acc: 0.8261 - val_loss: 0.4264 - val_acc: 0.8143\n",
      "AUC under ROC for high inclusion exons: 0.8190816653239967\n",
      "epoch : 44\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3895 - acc: 0.8257 - val_loss: 0.4900 - val_acc: 0.7703\n",
      "AUC under ROC for high inclusion exons: 0.8121395447315694\n",
      "epoch : 45\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3869 - acc: 0.8264 - val_loss: 0.4717 - val_acc: 0.7851\n",
      "AUC under ROC for high inclusion exons: 0.8103708351407739\n",
      "epoch : 46\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.3862 - acc: 0.8262 - val_loss: 0.4623 - val_acc: 0.7882\n",
      "AUC under ROC for high inclusion exons: 0.8189541116688356\n",
      "epoch : 47\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.3854 - acc: 0.8271 - val_loss: 0.4583 - val_acc: 0.7947\n",
      "AUC under ROC for high inclusion exons: 0.813418696164095\n",
      "epoch : 48\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 52us/step - loss: 0.3841 - acc: 0.8278 - val_loss: 0.4596 - val_acc: 0.7894\n",
      "AUC under ROC for high inclusion exons: 0.8055658837867429\n",
      "epoch : 49\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3812 - acc: 0.8294 - val_loss: 0.4407 - val_acc: 0.8006\n",
      "AUC under ROC for high inclusion exons: 0.8177570696742478\n"
     ]
    }
   ],
   "source": [
    "for i in range (50):\n",
    "    \n",
    "\n",
    "    \n",
    "    print('epoch :',i)\n",
    "    model.fit([train[:,:l-1,:4],train[:,l:(l*2)-1,:4],train[:,-1,0:3]], y_train,validation_data=([test[:,:l-1,:4],test[:,l:(l*2)-1,:4],test[:,-1,0:3]], y_test), epochs = 1, verbose = 1, batch_size = 256)\n",
    "    y_=model.predict([htest[:,:l-1,:4],htest[:,l:(l*2)-1,:4],htest[:,-1,0:3]])\n",
    "    print(\"AUC under ROC for high inclusion exons:\",roc_auc_score(hy_test, y_))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3809 - acc: 0.8293 - val_loss: 0.4695 - val_acc: 0.7886\n",
      "AUC under ROC for high inclusion exons: 0.8117883848712071\n",
      "epoch : 1\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3790 - acc: 0.8305 - val_loss: 0.4219 - val_acc: 0.8179\n",
      "AUC under ROC for high inclusion exons: 0.8170371919605048\n",
      "epoch : 2\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.3789 - acc: 0.8301 - val_loss: 0.4764 - val_acc: 0.7837\n",
      "AUC under ROC for high inclusion exons: 0.8074476875090372\n",
      "epoch : 3\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3776 - acc: 0.8307 - val_loss: 0.3936 - val_acc: 0.8393\n",
      "AUC under ROC for high inclusion exons: 0.8217814649563117\n",
      "epoch : 4\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.3788 - acc: 0.8305 - val_loss: 0.4688 - val_acc: 0.7857\n",
      "AUC under ROC for high inclusion exons: 0.8169104129226828\n",
      "epoch : 5\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3759 - acc: 0.8309 - val_loss: 0.4853 - val_acc: 0.7829\n",
      "AUC under ROC for high inclusion exons: 0.8110104108570366\n",
      "epoch : 6\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3739 - acc: 0.8323 - val_loss: 0.4619 - val_acc: 0.7921\n",
      "AUC under ROC for high inclusion exons: 0.816239594307079\n",
      "epoch : 7\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3728 - acc: 0.8333 - val_loss: 0.4346 - val_acc: 0.8094\n",
      "AUC under ROC for high inclusion exons: 0.8184028423292227\n",
      "epoch : 8\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3710 - acc: 0.8325 - val_loss: 0.4512 - val_acc: 0.7998\n",
      "AUC under ROC for high inclusion exons: 0.8173026275020139\n",
      "epoch : 9\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3735 - acc: 0.8318 - val_loss: 0.4879 - val_acc: 0.7784\n",
      "AUC under ROC for high inclusion exons: 0.8128911817562123\n",
      "epoch : 10\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.3709 - acc: 0.8331 - val_loss: 0.4470 - val_acc: 0.7996\n",
      "AUC under ROC for high inclusion exons: 0.8208366900084691\n",
      "epoch : 11\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3704 - acc: 0.8344 - val_loss: 0.4655 - val_acc: 0.7917\n",
      "AUC under ROC for high inclusion exons: 0.8160051434591311\n",
      "epoch : 12\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3666 - acc: 0.8357 - val_loss: 0.4981 - val_acc: 0.7772\n",
      "AUC under ROC for high inclusion exons: 0.8111250542232139\n",
      "epoch : 13\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.3692 - acc: 0.8342 - val_loss: 0.4436 - val_acc: 0.8059\n",
      "AUC under ROC for high inclusion exons: 0.8184100720910537\n",
      "epoch : 14\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3681 - acc: 0.8341 - val_loss: 0.4255 - val_acc: 0.8132\n",
      "AUC under ROC for high inclusion exons: 0.8274565697878581\n",
      "epoch : 15\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3655 - acc: 0.8358 - val_loss: 0.4764 - val_acc: 0.7916\n",
      "AUC under ROC for high inclusion exons: 0.8093362045816032\n",
      "epoch : 16\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3672 - acc: 0.8358 - val_loss: 0.4748 - val_acc: 0.7841\n",
      "AUC under ROC for high inclusion exons: 0.8210943793765878\n",
      "epoch : 17\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3646 - acc: 0.8362 - val_loss: 0.4570 - val_acc: 0.7943\n",
      "AUC under ROC for high inclusion exons: 0.814729606907521\n",
      "epoch : 18\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3633 - acc: 0.8385 - val_loss: 0.4410 - val_acc: 0.8059\n",
      "AUC under ROC for high inclusion exons: 0.8208872983412862\n",
      "epoch : 19\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.3650 - acc: 0.8368 - val_loss: 0.4466 - val_acc: 0.8026\n",
      "AUC under ROC for high inclusion exons: 0.8183109210716573\n",
      "epoch : 20\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3643 - acc: 0.8376 - val_loss: 0.4654 - val_acc: 0.7947\n",
      "AUC under ROC for high inclusion exons: 0.815037646402677\n",
      "epoch : 21\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.3623 - acc: 0.8371 - val_loss: 0.4445 - val_acc: 0.8067\n",
      "AUC under ROC for high inclusion exons: 0.8208335915391131\n",
      "epoch : 22\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3627 - acc: 0.8388 - val_loss: 0.4682 - val_acc: 0.7908\n",
      "AUC under ROC for high inclusion exons: 0.8181859494742929\n",
      "epoch : 23\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3601 - acc: 0.8385 - val_loss: 0.4271 - val_acc: 0.8139\n",
      "AUC under ROC for high inclusion exons: 0.8223768874842494\n",
      "epoch : 24\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3605 - acc: 0.8381 - val_loss: 0.4078 - val_acc: 0.8242\n",
      "AUC under ROC for high inclusion exons: 0.8301083431451528\n",
      "epoch : 25\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.3608 - acc: 0.8383 - val_loss: 0.4549 - val_acc: 0.7943\n",
      "AUC under ROC for high inclusion exons: 0.8254978207432193\n",
      "epoch : 26\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3611 - acc: 0.8377 - val_loss: 0.4627 - val_acc: 0.7992\n",
      "AUC under ROC for high inclusion exons: 0.8132072256305385\n",
      "epoch : 27\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3596 - acc: 0.8391 - val_loss: 0.4334 - val_acc: 0.8116\n",
      "AUC under ROC for high inclusion exons: 0.8224437627811859\n",
      "epoch : 28\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.3597 - acc: 0.8378 - val_loss: 0.4486 - val_acc: 0.8033\n",
      "AUC under ROC for high inclusion exons: 0.8196262213133378\n",
      "epoch : 29\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3595 - acc: 0.8389 - val_loss: 0.4202 - val_acc: 0.8214\n",
      "AUC under ROC for high inclusion exons: 0.8241153869988225\n",
      "epoch : 30\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3552 - acc: 0.8414 - val_loss: 0.4585 - val_acc: 0.7959\n",
      "AUC under ROC for high inclusion exons: 0.8200228253909235\n",
      "epoch : 31\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.3568 - acc: 0.8401 - val_loss: 0.4500 - val_acc: 0.8010\n",
      "AUC under ROC for high inclusion exons: 0.8187777571213155\n",
      "epoch : 32\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3575 - acc: 0.8383 - val_loss: 0.4035 - val_acc: 0.8267\n",
      "AUC under ROC for high inclusion exons: 0.8288601764061887\n",
      "epoch : 33\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3563 - acc: 0.8410 - val_loss: 0.4244 - val_acc: 0.8138\n",
      "AUC under ROC for high inclusion exons: 0.8270705521472393\n",
      "epoch : 34\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3549 - acc: 0.8408 - val_loss: 0.4488 - val_acc: 0.8002\n",
      "AUC under ROC for high inclusion exons: 0.8196887071120199\n",
      "epoch : 35\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3549 - acc: 0.8393 - val_loss: 0.4703 - val_acc: 0.7941\n",
      "AUC under ROC for high inclusion exons: 0.8115356014129019\n",
      "epoch : 36\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.3537 - acc: 0.8418 - val_loss: 0.4381 - val_acc: 0.8077\n",
      "AUC under ROC for high inclusion exons: 0.8228419160934497\n",
      "epoch : 37\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3543 - acc: 0.8415 - val_loss: 0.4379 - val_acc: 0.8077\n",
      "AUC under ROC for high inclusion exons: 0.8143386833570883\n",
      "epoch : 38\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3518 - acc: 0.8432 - val_loss: 0.4226 - val_acc: 0.8189\n",
      "AUC under ROC for high inclusion exons: 0.8209694077792237\n",
      "epoch : 39\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3527 - acc: 0.8420 - val_loss: 0.3911 - val_acc: 0.8358\n",
      "AUC under ROC for high inclusion exons: 0.8332000991510193\n",
      "epoch : 40\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3512 - acc: 0.8419 - val_loss: 0.4105 - val_acc: 0.8250\n",
      "AUC under ROC for high inclusion exons: 0.8211620292908636\n",
      "epoch : 41\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3514 - acc: 0.8421 - val_loss: 0.4084 - val_acc: 0.8297\n",
      "AUC under ROC for high inclusion exons: 0.8222020821714073\n",
      "epoch : 42\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3527 - acc: 0.8423 - val_loss: 0.4288 - val_acc: 0.8185\n",
      "AUC under ROC for high inclusion exons: 0.818165809423478\n",
      "epoch : 43\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3520 - acc: 0.8445 - val_loss: 0.4176 - val_acc: 0.8251\n",
      "AUC under ROC for high inclusion exons: 0.8218723533907584\n",
      "epoch : 44\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3491 - acc: 0.8438 - val_loss: 0.3728 - val_acc: 0.8530\n",
      "AUC under ROC for high inclusion exons: 0.833442812583917\n",
      "epoch : 45\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3505 - acc: 0.8432 - val_loss: 0.4081 - val_acc: 0.8289\n",
      "AUC under ROC for high inclusion exons: 0.8244507963066244\n",
      "epoch : 46\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.3474 - acc: 0.8436 - val_loss: 0.4077 - val_acc: 0.8261\n",
      "AUC under ROC for high inclusion exons: 0.8246707876309103\n",
      "epoch : 47\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 56us/step - loss: 0.3502 - acc: 0.8440 - val_loss: 0.4030 - val_acc: 0.8301\n",
      "AUC under ROC for high inclusion exons: 0.8272931255293219\n",
      "epoch : 48\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 52us/step - loss: 0.3494 - acc: 0.8442 - val_loss: 0.4029 - val_acc: 0.8289\n",
      "AUC under ROC for high inclusion exons: 0.8258828055607197\n",
      "epoch : 49\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.3485 - acc: 0.8438 - val_loss: 0.3949 - val_acc: 0.8328\n",
      "AUC under ROC for high inclusion exons: 0.8293277870731859\n"
     ]
    }
   ],
   "source": [
    "for i in range (50):\n",
    "    \n",
    "\n",
    "    \n",
    "    print('epoch :',i)\n",
    "    model.fit([train[:,:l-1,:4],train[:,l:(l*2)-1,:4],train[:,-1,0:3]], y_train,validation_data=([test[:,:l-1,:4],test[:,l:(l*2)-1,:4],test[:,-1,0:3]], y_test), epochs = 1, verbose = 1, batch_size = 256)\n",
    "    y_=model.predict([htest[:,:l-1,:4],htest[:,l:(l*2)-1,:4],htest[:,-1,0:3]])\n",
    "    print(\"AUC under ROC for high inclusion exons:\",roc_auc_score(hy_test, y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3487 - acc: 0.8440 - val_loss: 0.4225 - val_acc: 0.8177\n",
      "AUC under ROC for high inclusion exons: 0.8211065150482328\n",
      "epoch : 1\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3492 - acc: 0.8429 - val_loss: 0.3702 - val_acc: 0.8530\n",
      "AUC under ROC for high inclusion exons: 0.8344061783478961\n",
      "epoch : 2\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3452 - acc: 0.8458 - val_loss: 0.3966 - val_acc: 0.8371\n",
      "AUC under ROC for high inclusion exons: 0.8263165912705791\n",
      "epoch : 3\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.3492 - acc: 0.8439 - val_loss: 0.4282 - val_acc: 0.8214\n",
      "AUC under ROC for high inclusion exons: 0.8207765280618041\n",
      "epoch : 4\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3472 - acc: 0.8450 - val_loss: 0.3999 - val_acc: 0.8338\n",
      "AUC under ROC for high inclusion exons: 0.8267658693272191\n",
      "epoch : 5\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3481 - acc: 0.8446 - val_loss: 0.4139 - val_acc: 0.8232\n",
      "AUC under ROC for high inclusion exons: 0.8218537625746214\n",
      "epoch : 6\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3458 - acc: 0.8467 - val_loss: 0.3954 - val_acc: 0.8352\n",
      "AUC under ROC for high inclusion exons: 0.8329189130569499\n",
      "epoch : 7\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.3460 - acc: 0.8454 - val_loss: 0.3603 - val_acc: 0.8607\n",
      "AUC under ROC for high inclusion exons: 0.8297946231228439\n",
      "epoch : 8\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3445 - acc: 0.8460 - val_loss: 0.3926 - val_acc: 0.8356\n",
      "AUC under ROC for high inclusion exons: 0.8252990022928672\n",
      "epoch : 9\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3447 - acc: 0.8456 - val_loss: 0.3811 - val_acc: 0.8426\n",
      "AUC under ROC for high inclusion exons: 0.8302893453967074\n",
      "epoch : 10\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3457 - acc: 0.8444 - val_loss: 0.3966 - val_acc: 0.8356\n",
      "AUC under ROC for high inclusion exons: 0.8295198921732665\n",
      "epoch : 11\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3442 - acc: 0.8467 - val_loss: 0.4706 - val_acc: 0.7959\n",
      "AUC under ROC for high inclusion exons: 0.8157750821094379\n",
      "epoch : 12\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.3444 - acc: 0.8450 - val_loss: 0.4004 - val_acc: 0.8346\n",
      "AUC under ROC for high inclusion exons: 0.8222395220094606\n",
      "epoch : 13\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 52us/step - loss: 0.3466 - acc: 0.8450 - val_loss: 0.4058 - val_acc: 0.8277\n",
      "AUC under ROC for high inclusion exons: 0.8286311478796142\n",
      "epoch : 14\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3427 - acc: 0.8464 - val_loss: 0.3674 - val_acc: 0.8536\n",
      "AUC under ROC for high inclusion exons: 0.8339827208692241\n",
      "epoch : 15\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3466 - acc: 0.8439 - val_loss: 0.3904 - val_acc: 0.8420\n",
      "AUC under ROC for high inclusion exons: 0.8247322406064738\n",
      "epoch : 16\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3433 - acc: 0.8460 - val_loss: 0.3706 - val_acc: 0.8521\n",
      "AUC under ROC for high inclusion exons: 0.8349644192435602\n",
      "epoch : 17\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3416 - acc: 0.8471 - val_loss: 0.4001 - val_acc: 0.8299\n",
      "AUC under ROC for high inclusion exons: 0.8309694594203796\n",
      "epoch : 18\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3407 - acc: 0.8469 - val_loss: 0.3906 - val_acc: 0.8403\n",
      "AUC under ROC for high inclusion exons: 0.8291940364793126\n",
      "epoch : 19\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3417 - acc: 0.8470 - val_loss: 0.3831 - val_acc: 0.8473\n",
      "AUC under ROC for high inclusion exons: 0.823519706265105\n",
      "epoch : 20\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3429 - acc: 0.8467 - val_loss: 0.3806 - val_acc: 0.8481\n",
      "AUC under ROC for high inclusion exons: 0.8253767222325504\n",
      "epoch : 21\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3432 - acc: 0.8470 - val_loss: 0.4027 - val_acc: 0.8316\n",
      "AUC under ROC for high inclusion exons: 0.8274423684699759\n",
      "epoch : 22\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.3425 - acc: 0.8471 - val_loss: 0.3833 - val_acc: 0.8450\n",
      "AUC under ROC for high inclusion exons: 0.8339501869409844\n",
      "epoch : 23\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3416 - acc: 0.8466 - val_loss: 0.3694 - val_acc: 0.8550\n",
      "AUC under ROC for high inclusion exons: 0.8305336080642829\n",
      "epoch : 24\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3429 - acc: 0.8471 - val_loss: 0.3764 - val_acc: 0.8519\n",
      "AUC under ROC for high inclusion exons: 0.8372257854619818\n",
      "epoch : 25\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3404 - acc: 0.8488 - val_loss: 0.4009 - val_acc: 0.8356\n",
      "AUC under ROC for high inclusion exons: 0.8304453016876329\n",
      "epoch : 26\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3407 - acc: 0.8483 - val_loss: 0.3645 - val_acc: 0.8589\n",
      "AUC under ROC for high inclusion exons: 0.8388431864658858\n",
      "epoch : 27\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3387 - acc: 0.8482 - val_loss: 0.4088 - val_acc: 0.8312\n",
      "AUC under ROC for high inclusion exons: 0.8255871599429881\n",
      "epoch : 28\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3393 - acc: 0.8487 - val_loss: 0.3810 - val_acc: 0.8470\n",
      "AUC under ROC for high inclusion exons: 0.8309508686042428\n",
      "epoch : 29\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3394 - acc: 0.8495 - val_loss: 0.3727 - val_acc: 0.8556\n",
      "AUC under ROC for high inclusion exons: 0.8302730784325876\n",
      "epoch : 30\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3407 - acc: 0.8479 - val_loss: 0.3919 - val_acc: 0.8422\n",
      "AUC under ROC for high inclusion exons: 0.8288209291276776\n",
      "epoch : 31\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3401 - acc: 0.8481 - val_loss: 0.3730 - val_acc: 0.8528\n",
      "AUC under ROC for high inclusion exons: 0.8343191630001446\n",
      "epoch : 32\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3387 - acc: 0.8469 - val_loss: 0.3790 - val_acc: 0.8493\n",
      "AUC under ROC for high inclusion exons: 0.8354547520191693\n",
      "epoch : 33\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3397 - acc: 0.8477 - val_loss: 0.3876 - val_acc: 0.8440\n",
      "AUC under ROC for high inclusion exons: 0.8300210695916217\n",
      "epoch : 34\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3390 - acc: 0.8495 - val_loss: 0.3858 - val_acc: 0.8436\n",
      "AUC under ROC for high inclusion exons: 0.834612484765859\n",
      "epoch : 35\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3380 - acc: 0.8499 - val_loss: 0.3773 - val_acc: 0.8523\n",
      "AUC under ROC for high inclusion exons: 0.8323087727995703\n",
      "epoch : 36\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3376 - acc: 0.8501 - val_loss: 0.3604 - val_acc: 0.8627\n",
      "AUC under ROC for high inclusion exons: 0.8363419470781434\n",
      "epoch : 37\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3366 - acc: 0.8493 - val_loss: 0.3564 - val_acc: 0.8654\n",
      "AUC under ROC for high inclusion exons: 0.8367137634008801\n",
      "epoch : 38\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3376 - acc: 0.8505 - val_loss: 0.3862 - val_acc: 0.8448\n",
      "AUC under ROC for high inclusion exons: 0.8279427712709921\n",
      "epoch : 39\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3370 - acc: 0.8500 - val_loss: 0.3877 - val_acc: 0.8424\n",
      "AUC under ROC for high inclusion exons: 0.8323247815579102\n",
      "epoch : 40\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3366 - acc: 0.8490 - val_loss: 0.3551 - val_acc: 0.8658\n",
      "AUC under ROC for high inclusion exons: 0.8409979136973003\n",
      "epoch : 41\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3375 - acc: 0.8505 - val_loss: 0.3442 - val_acc: 0.8729\n",
      "AUC under ROC for high inclusion exons: 0.8458542480014872\n",
      "epoch : 42\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3369 - acc: 0.8495 - val_loss: 0.3781 - val_acc: 0.8497\n",
      "AUC under ROC for high inclusion exons: 0.8338022350292289\n",
      "epoch : 43\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3367 - acc: 0.8497 - val_loss: 0.3781 - val_acc: 0.8542\n",
      "AUC under ROC for high inclusion exons: 0.8285735679907459\n",
      "epoch : 44\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3366 - acc: 0.8494 - val_loss: 0.3410 - val_acc: 0.8737\n",
      "AUC under ROC for high inclusion exons: 0.8482380037594763\n",
      "epoch : 45\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3384 - acc: 0.8488 - val_loss: 0.3391 - val_acc: 0.8788\n",
      "AUC under ROC for high inclusion exons: 0.8477835615872427\n",
      "epoch : 46\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3350 - acc: 0.8515 - val_loss: 0.3430 - val_acc: 0.8766\n",
      "AUC under ROC for high inclusion exons: 0.8375219474912725\n",
      "epoch : 47\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.3348 - acc: 0.8500 - val_loss: 0.3558 - val_acc: 0.8662\n",
      "AUC under ROC for high inclusion exons: 0.837666026316333\n",
      "epoch : 48\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3386 - acc: 0.8482 - val_loss: 0.3552 - val_acc: 0.8670\n",
      "AUC under ROC for high inclusion exons: 0.8390670508768668\n",
      "epoch : 49\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.3342 - acc: 0.8514 - val_loss: 0.3546 - val_acc: 0.8613\n",
      "AUC under ROC for high inclusion exons: 0.8451772324471711\n",
      "epoch : 50\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.3341 - acc: 0.8504 - val_loss: 0.3442 - val_acc: 0.8721\n",
      "AUC under ROC for high inclusion exons: 0.8495285162463077\n",
      "epoch : 51\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3320 - acc: 0.8520 - val_loss: 0.3678 - val_acc: 0.8538\n",
      "AUC under ROC for high inclusion exons: 0.8358859556712316\n",
      "epoch : 52\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3328 - acc: 0.8516 - val_loss: 0.3501 - val_acc: 0.8705\n",
      "AUC under ROC for high inclusion exons: 0.8413748941356303\n",
      "epoch : 53\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3342 - acc: 0.8510 - val_loss: 0.3439 - val_acc: 0.8729\n",
      "AUC under ROC for high inclusion exons: 0.8490244985643758\n",
      "epoch : 54\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3334 - acc: 0.8516 - val_loss: 0.3437 - val_acc: 0.8747\n",
      "AUC under ROC for high inclusion exons: 0.8441227200429653\n",
      "epoch : 55\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3344 - acc: 0.8516 - val_loss: 0.3629 - val_acc: 0.8593\n",
      "AUC under ROC for high inclusion exons: 0.8400683728904588\n",
      "epoch : 56\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3358 - acc: 0.8502 - val_loss: 0.3174 - val_acc: 0.8900\n",
      "AUC under ROC for high inclusion exons: 0.8545449381338952\n",
      "epoch : 57\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3346 - acc: 0.8518 - val_loss: 0.3570 - val_acc: 0.8631\n",
      "AUC under ROC for high inclusion exons: 0.8417456776352481\n",
      "epoch : 58\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.3320 - acc: 0.8518 - val_loss: 0.3561 - val_acc: 0.8625\n",
      "AUC under ROC for high inclusion exons: 0.8447452541777695\n",
      "epoch : 59\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3327 - acc: 0.8512 - val_loss: 0.3351 - val_acc: 0.8796\n",
      "AUC under ROC for high inclusion exons: 0.8481822313110657\n",
      "epoch : 60\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3341 - acc: 0.8504 - val_loss: 0.3253 - val_acc: 0.8831\n",
      "AUC under ROC for high inclusion exons: 0.8553564788994237\n",
      "epoch : 61\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 52us/step - loss: 0.3322 - acc: 0.8525 - val_loss: 0.3436 - val_acc: 0.8723\n",
      "AUC under ROC for high inclusion exons: 0.8437728512115014\n",
      "epoch : 62\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.3335 - acc: 0.8501 - val_loss: 0.3291 - val_acc: 0.8835\n",
      "AUC under ROC for high inclusion exons: 0.8534842287909773\n",
      "epoch : 63\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3312 - acc: 0.8520 - val_loss: 0.3514 - val_acc: 0.8631\n",
      "AUC under ROC for high inclusion exons: 0.8460365412819401\n",
      "epoch : 64\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.3308 - acc: 0.8531 - val_loss: 0.3421 - val_acc: 0.8709\n",
      "AUC under ROC for high inclusion exons: 0.8502628534837123\n",
      "epoch : 65\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 48us/step - loss: 0.3324 - acc: 0.8525 - val_loss: 0.3408 - val_acc: 0.8754\n",
      "AUC under ROC for high inclusion exons: 0.8427836648695545\n",
      "epoch : 66\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 47us/step - loss: 0.3327 - acc: 0.8507 - val_loss: 0.3369 - val_acc: 0.8772\n",
      "AUC under ROC for high inclusion exons: 0.850643448802958\n",
      "epoch : 67\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3322 - acc: 0.8527 - val_loss: 0.3517 - val_acc: 0.8650\n",
      "AUC under ROC for high inclusion exons: 0.8436873850984281\n",
      "epoch : 68\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 52us/step - loss: 0.3324 - acc: 0.8520 - val_loss: 0.3466 - val_acc: 0.8690\n",
      "AUC under ROC for high inclusion exons: 0.8424028113445291\n",
      "epoch : 69\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3325 - acc: 0.8518 - val_loss: 0.3509 - val_acc: 0.8676\n",
      "AUC under ROC for high inclusion exons: 0.8434204003222407\n",
      "epoch : 70\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3313 - acc: 0.8519 - val_loss: 0.3521 - val_acc: 0.8678\n",
      "AUC under ROC for high inclusion exons: 0.839768079568693\n",
      "epoch : 71\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.3326 - acc: 0.8514 - val_loss: 0.3360 - val_acc: 0.8776\n",
      "AUC under ROC for high inclusion exons: 0.8501693829914688\n",
      "epoch : 72\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3304 - acc: 0.8542 - val_loss: 0.3530 - val_acc: 0.8640\n",
      "AUC under ROC for high inclusion exons: 0.8418422465968478\n",
      "epoch : 73\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.3315 - acc: 0.8530 - val_loss: 0.3340 - val_acc: 0.8798\n",
      "AUC under ROC for high inclusion exons: 0.8493648137819916\n",
      "epoch : 74\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3302 - acc: 0.8532 - val_loss: 0.3331 - val_acc: 0.8806\n",
      "AUC under ROC for high inclusion exons: 0.8482643407490033\n",
      "epoch : 75\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.3310 - acc: 0.8531 - val_loss: 0.3351 - val_acc: 0.8809\n",
      "AUC under ROC for high inclusion exons: 0.845003201751668\n",
      "epoch : 76\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.3307 - acc: 0.8517 - val_loss: 0.3359 - val_acc: 0.8788\n",
      "AUC under ROC for high inclusion exons: 0.8462087645369853\n",
      "epoch : 77\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3292 - acc: 0.8536 - val_loss: 0.3418 - val_acc: 0.8750\n",
      "AUC under ROC for high inclusion exons: 0.8476756315713372\n",
      "epoch : 78\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 55us/step - loss: 0.3320 - acc: 0.8516 - val_loss: 0.3419 - val_acc: 0.8760\n",
      "AUC under ROC for high inclusion exons: 0.8486351242486211\n",
      "epoch : 79\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3323 - acc: 0.8524 - val_loss: 0.3327 - val_acc: 0.8807\n",
      "AUC under ROC for high inclusion exons: 0.8519331866724504\n",
      "epoch : 80\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3304 - acc: 0.8531 - val_loss: 0.3313 - val_acc: 0.8835\n",
      "AUC under ROC for high inclusion exons: 0.8493364111462272\n",
      "epoch : 81\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3294 - acc: 0.8537 - val_loss: 0.3381 - val_acc: 0.8764\n",
      "AUC under ROC for high inclusion exons: 0.8508438164879881\n",
      "epoch : 82\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 52us/step - loss: 0.3290 - acc: 0.8546 - val_loss: 0.3201 - val_acc: 0.8878\n",
      "AUC under ROC for high inclusion exons: 0.8583364318026894\n",
      "epoch : 83\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3293 - acc: 0.8530 - val_loss: 0.3260 - val_acc: 0.8841\n",
      "AUC under ROC for high inclusion exons: 0.8558754725165769\n",
      "epoch : 84\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3286 - acc: 0.8540 - val_loss: 0.3313 - val_acc: 0.8825\n",
      "AUC under ROC for high inclusion exons: 0.8480913428766189\n",
      "epoch : 85\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3311 - acc: 0.8517 - val_loss: 0.3615 - val_acc: 0.8593\n",
      "AUC under ROC for high inclusion exons: 0.8429533060668031\n",
      "epoch : 86\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3304 - acc: 0.8541 - val_loss: 0.3353 - val_acc: 0.8796\n",
      "AUC under ROC for high inclusion exons: 0.8458754208754208\n",
      "epoch : 87\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3280 - acc: 0.8531 - val_loss: 0.3257 - val_acc: 0.8864\n",
      "AUC under ROC for high inclusion exons: 0.8502863502096631\n",
      "epoch : 88\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 50us/step - loss: 0.3279 - acc: 0.8545 - val_loss: 0.3429 - val_acc: 0.8729\n",
      "AUC under ROC for high inclusion exons: 0.8493606824895168\n",
      "epoch : 89\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3285 - acc: 0.8526 - val_loss: 0.3332 - val_acc: 0.8819\n",
      "AUC under ROC for high inclusion exons: 0.847029858916362\n",
      "epoch : 90\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 52us/step - loss: 0.3295 - acc: 0.8531 - val_loss: 0.3248 - val_acc: 0.8845\n",
      "AUC under ROC for high inclusion exons: 0.8507859783933404\n",
      "epoch : 91\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 52us/step - loss: 0.3279 - acc: 0.8524 - val_loss: 0.3439 - val_acc: 0.8709\n",
      "AUC under ROC for high inclusion exons: 0.8482563363698333\n",
      "epoch : 92\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3280 - acc: 0.8523 - val_loss: 0.3268 - val_acc: 0.8827\n",
      "AUC under ROC for high inclusion exons: 0.8571533329202041\n",
      "epoch : 93\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3283 - acc: 0.8547 - val_loss: 0.3313 - val_acc: 0.8811\n",
      "AUC under ROC for high inclusion exons: 0.844413459750883\n",
      "epoch : 94\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3272 - acc: 0.8531 - val_loss: 0.3414 - val_acc: 0.8760\n",
      "AUC under ROC for high inclusion exons: 0.8481615748486914\n",
      "epoch : 95\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3267 - acc: 0.8562 - val_loss: 0.3365 - val_acc: 0.8784\n",
      "AUC under ROC for high inclusion exons: 0.8515843506641053\n",
      "epoch : 96\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67052/67052 [==============================] - 4s 54us/step - loss: 0.3284 - acc: 0.8538 - val_loss: 0.3370 - val_acc: 0.8774\n",
      "AUC under ROC for high inclusion exons: 0.8498838073991449\n",
      "epoch : 97\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 49us/step - loss: 0.3285 - acc: 0.8542 - val_loss: 0.3289 - val_acc: 0.8817\n",
      "AUC under ROC for high inclusion exons: 0.8505763153002417\n",
      "epoch : 98\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 3s 51us/step - loss: 0.3275 - acc: 0.8545 - val_loss: 0.3213 - val_acc: 0.8886\n",
      "AUC under ROC for high inclusion exons: 0.850736402883642\n",
      "epoch : 99\n",
      "Train on 67052 samples, validate on 5090 samples\n",
      "Epoch 1/1\n",
      "67052/67052 [==============================] - 4s 53us/step - loss: 0.3267 - acc: 0.8551 - val_loss: 0.3280 - val_acc: 0.8833\n",
      "AUC under ROC for high inclusion exons: 0.8543326929829997\n"
     ]
    }
   ],
   "source": [
    "for i in range (100):\n",
    "    \n",
    "\n",
    "    \n",
    "    print('epoch :',i)\n",
    "    model.fit([train[:,:l-1,:4],train[:,l:(l*2)-1,:4],train[:,-1,0:3]], y_train,validation_data=([test[:,:l-1,:4],test[:,l:(l*2)-1,:4],test[:,-1,0:3]], y_test), epochs = 1, verbose = 1, batch_size = 256)\n",
    "    y_=model.predict([htest[:,:l-1,:4],htest[:,l:(l*2)-1,:4],htest[:,-1,0:3]])\n",
    "    print(\"AUC under ROC for high inclusion exons:\",roc_auc_score(hy_test, y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8543326929829997, 0.9221897109767746, 0.8936759385600357)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "y1_=model.predict([htest[:,:l-1,:4],htest[:,l:(l*2)-1,:4],htest[:,-1,0:3]])\n",
    "ac1 = roc_auc_score(hy_test, y1_)\n",
    "\n",
    "y2_=model.predict([ltest[:,:l-1,:4],ltest[:,l:(l*2)-1,:4],ltest[:,-1,0:3]])\n",
    "ac3 = roc_auc_score(ly_test, y2_)\n",
    "\n",
    "y_=model.predict([test[:,:l-1,:4],test[:,l:(l*2)-1,:4],test[:,-1,0:3]])\n",
    "ac2 = roc_auc_score(y_test, y_)\n",
    "ac1,ac3,ac2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_AUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.92354215, 0.92316938, 0.93189952, 0.9263425 , 0.94484614,\n",
       "       0.9219014 , 0.88352273, 0.9243855 , 0.86013393, 0.85121588])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_AUC2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
